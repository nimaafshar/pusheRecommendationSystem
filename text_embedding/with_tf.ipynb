{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/iwyoo/LSTM-autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn_cell import LSTMCell\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class LSTMAutoencoder(object):\n",
    "\n",
    "    \"\"\"Basic version of LSTM-autoencoder.\n",
    "  (cf. http://arxiv.org/abs/1502.04681)\n",
    "  Usage:\n",
    "    ae = LSTMAutoencoder(hidden_num, inputs)\n",
    "    sess.run(ae.train)\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_num,\n",
    "        inputs,\n",
    "        cell=None,\n",
    "        optimizer=None,\n",
    "        reverse=True,\n",
    "        decode_without_input=False,\n",
    "        ):\n",
    "        \"\"\"\n",
    "    Args:\n",
    "      hidden_num : number of hidden elements of each LSTM unit.\n",
    "      inputs : a list of input tensors with size \n",
    "              (batch_num x elem_num)\n",
    "      cell : an rnn cell object (the default option \n",
    "            is `tf.python.ops.rnn_cell.LSTMCell`)\n",
    "      optimizer : optimizer for rnn (the default option is\n",
    "              `tf.train.AdamOptimizer`)\n",
    "      reverse : Option to decode in reverse order.\n",
    "      decode_without_input : Option to decode without input.\n",
    "    \"\"\"\n",
    "\n",
    "        self.batch_num = inputs[0].get_shape().as_list()[0]\n",
    "        self.elem_num = inputs[0].get_shape().as_list()[1]\n",
    "\n",
    "        if cell is None:\n",
    "            self._enc_cell = LSTMCell(hidden_num)\n",
    "            self._dec_cell = LSTMCell(hidden_num)\n",
    "        else:\n",
    "            self._enc_cell = cell\n",
    "            self._dec_cell = cell\n",
    "\n",
    "        with tf.variable_scope('encoder'):\n",
    "            (self.z_codes, self.enc_state) = tf.contrib.rnn.static_rnn(self._enc_cell, inputs, dtype=tf.float32)\n",
    "\n",
    "        with tf.variable_scope('decoder') as vs:\n",
    "            dec_weight_ = tf.Variable(tf.truncated_normal([hidden_num,\n",
    "                    self.elem_num], dtype=tf.float32), name='dec_weight'\n",
    "                    )\n",
    "            dec_bias_ = tf.Variable(tf.constant(0.1,\n",
    "                                    shape=[self.elem_num],\n",
    "                                    dtype=tf.float32), name='dec_bias')\n",
    "\n",
    "            if decode_without_input:\n",
    "                dec_inputs = [tf.zeros(tf.shape(inputs[0]),\n",
    "                              dtype=tf.float32) for _ in\n",
    "                              range(len(inputs))]\n",
    "                (dec_outputs, dec_state) = tf.contrib.rnn.static_rnn(self._dec_cell, dec_inputs, initial_state=self.enc_state,\n",
    "                        dtype=tf.float32)\n",
    "                if reverse:\n",
    "                    dec_outputs = dec_outputs[::-1]\n",
    "                dec_output_ = tf.transpose(tf.stack(dec_outputs), [1, 0,\n",
    "                        2])\n",
    "                dec_weight_ = tf.tile(tf.expand_dims(dec_weight_, 0),\n",
    "                        [self.batch_num, 1, 1])\n",
    "                self.output_ = tf.matmul(dec_output_, dec_weight_) + dec_bias_\n",
    "            else:\n",
    "\n",
    "                dec_state = self.enc_state\n",
    "                dec_input_ = tf.zeros(tf.shape(inputs[0]),\n",
    "                        dtype=tf.float32)\n",
    "                dec_outputs = []\n",
    "                for step in range(len(inputs)):\n",
    "                    if step > 0:\n",
    "                        vs.reuse_variables()\n",
    "                    (dec_input_, dec_state) = \\\n",
    "                        self._dec_cell(dec_input_, dec_state)\n",
    "                    dec_input_ = tf.matmul(dec_input_, dec_weight_) \\\n",
    "                        + dec_bias_\n",
    "                    dec_outputs.append(dec_input_)\n",
    "                if reverse:\n",
    "                    dec_outputs = dec_outputs[::-1]\n",
    "                self.output_ = tf.transpose(tf.stack(dec_outputs), [1,\n",
    "                        0, 2])\n",
    "\n",
    "        self.input_ = tf.transpose(tf.stack(inputs), [1, 0, 2])\n",
    "        self.loss = tf.reduce_mean(tf.square(self.input_\n",
    "                                   - self.output_))\n",
    "\n",
    "        if optimizer is None:\n",
    "            self.train = tf.train.AdamOptimizer().minimize(self.loss)\n",
    "        else:\n",
    "            self.train = optimizer.minimize(self.loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(2016)\n",
    "np.random.seed(2016)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "batch_num = 128\n",
    "hidden_num = 12\n",
    "step_num = 67\n",
    "elem_num = 2000\n",
    "iteration = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6347, 2000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "notifs_df = pd.read_csv('/Users/vahid/data/recommender/notifs_corrected.csv')\n",
    "\n",
    "input_data = np.zeros([notifs_df.shape[0], 2000])\n",
    "\n",
    "for index, row in notifs_df.iterrows():\n",
    "    if type(row.text) == str:\n",
    "        words = [int(word) for word in row.text.split(' ')]\n",
    "        for idx, word in enumerate(words):\n",
    "            input_data[index, word] = 1 \n",
    "            \n",
    "input_data.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# placeholder list\n",
    "p_input = tf.placeholder(tf.float32, shape=(batch_num, step_num, elem_num))\n",
    "p_inputs = [tf.squeeze(t, [1]) for t in tf.split(p_input, step_num, 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.LSTMCell(hidden_num, use_peepholes=True)\n",
    "ae = LSTMAutoencoder(hidden_num, p_inputs, cell=cell, decode_without_input=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:45<00:00,  1.08it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1: 0.0030840177 45.44552302360535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:40<00:00,  1.20it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 2: 0.0006657991 40.75128197669983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:37<00:00,  1.32it/s]\n",
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 3: 0.00019930373 37.22128891944885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 15/49 [00:12<00:27,  1.22it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e914ea657025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_num\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mp_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iter %d:'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(iteration):\n",
    "        \"\"\"Random sequences.\n",
    "          Every sequence has size batch_num * step_num * elem_num \n",
    "          Each step number increases 1 by 1.\n",
    "          An initial number of each sequence is in the range from 0 to 19.\n",
    "          (ex. [8. 9. 10. 11. 12. 13. 14. 15])\n",
    "        \"\"\"\n",
    "#         r = np.random.randint(20, size=batch_num).reshape([batch_num, 1, 1])\n",
    "#         r = np.tile(r, (1, step_num, elem_num))\n",
    "        \n",
    "#         d = np.linspace(0, step_num, step_num, endpoint=False).reshape([1, step_num, elem_num])\n",
    "#         d = np.tile(d, (batch_num, 1, 1))\n",
    "#         random_sequences = r + d\n",
    "#         print(random_sequences.shape)\n",
    "        s_time = time.time()\n",
    "        for batch_idx in tqdm(range(input_data.shape[0] // batch_num)):\n",
    "            batch_data = input_data[batch_idx * batch_num : ( batch_idx + 1 ) * batch_num]\n",
    "            (loss_val, _) = sess.run([ae.loss, ae.train], {p_input: batch_data})\n",
    "        print('iter %d:' % (i + 1), loss_val, time.time() - s_time)\n",
    "\n",
    "    (input_, output_) = sess.run([ae.input_, ae.output_], {p_input: r + d})\n",
    "    print('train result :')\n",
    "    print('input :', input_[0, :, :].flatten())\n",
    "    print('output :', output_[0, :, :].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5500, 2000) (847, 2000)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer dense_39 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    470\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 471\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'numpy.ndarray'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-703e8b40e6a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    283\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer dense_39 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 8   # 32 floats -> compression factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder; 784 = 28 x 28\n",
    "input_dim = 2000\n",
    "\n",
    "my_epochs = 100\n",
    "\n",
    "encoded = Dense(512, activation='relu')(x_train)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(latent_dim, activation='relu')(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(512, activation='relu')(decoded)\n",
    "decoded = Dense(x_train.shape[1], activation='sigmoid')(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# Separate Encoder model\n",
    "\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# Separate Decoder model\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim, ))\n",
    "# retrieve the layers of the autoencoder model\n",
    "decoder_layer1 = autoencoder.layers[-3]\n",
    "decoder_layer2 = autoencoder.layers[-2]\n",
    "decoder_layer3 = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer3(decoder_layer2(decoder_layer1(encoded_input))))\n",
    "\n",
    "# Train to reconstruct MNIST digits\n",
    "\n",
    "# configure model to use a per-pixel binary crossentropy loss, and the Adadelta optimizer\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 1026564   \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 2000)              1027536   \n",
      "=================================================================\n",
      "Total params: 2,054,100\n",
      "Trainable params: 2,054,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VAE loss = mse_loss or xent_loss + kl_loss\n",
    "\n",
    "reconstruction_loss = mse(inputs, outputs)\n",
    "\n",
    "reconstruction_loss *= original_dim\n",
    "vae_loss = K.mean(reconstruction_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5500 samples, validate on 847 samples\n",
      "Epoch 1/50\n",
      "5500/5500 [==============================] - 4s 749us/step - loss: 187.6390 - val_loss: 18.8190\n",
      "Epoch 2/50\n",
      "5500/5500 [==============================] - 2s 387us/step - loss: 16.5498 - val_loss: 16.4903\n",
      "Epoch 3/50\n",
      "5500/5500 [==============================] - 3s 480us/step - loss: 15.7478 - val_loss: 15.7258\n",
      "Epoch 4/50\n",
      "5500/5500 [==============================] - 3s 457us/step - loss: 15.4137 - val_loss: 15.4451\n",
      "Epoch 5/50\n",
      "5500/5500 [==============================] - 3s 480us/step - loss: 15.5207 - val_loss: 15.2056\n",
      "Epoch 6/50\n",
      "5500/5500 [==============================] - 2s 387us/step - loss: 15.3719 - val_loss: 15.3043\n",
      "Epoch 7/50\n",
      "5500/5500 [==============================] - 2s 386us/step - loss: 15.2468 - val_loss: 15.0886\n",
      "Epoch 8/50\n",
      "5500/5500 [==============================] - 2s 403us/step - loss: 15.2565 - val_loss: 15.1823\n",
      "Epoch 9/50\n",
      "5500/5500 [==============================] - 2s 387us/step - loss: 15.1128 - val_loss: 15.1252\n",
      "Epoch 10/50\n",
      "5500/5500 [==============================] - 2s 410us/step - loss: 15.0781 - val_loss: 15.1982\n",
      "Epoch 11/50\n",
      "5500/5500 [==============================] - 2s 395us/step - loss: 15.1264 - val_loss: 15.2035\n",
      "Epoch 12/50\n",
      "5500/5500 [==============================] - 2s 364us/step - loss: 15.1204 - val_loss: 15.2836\n",
      "Epoch 13/50\n",
      "5500/5500 [==============================] - 2s 378us/step - loss: 15.1261 - val_loss: 15.1994\n",
      "Epoch 14/50\n",
      "5500/5500 [==============================] - 2s 409us/step - loss: 15.1799 - val_loss: 15.0379\n",
      "Epoch 15/50\n",
      "5500/5500 [==============================] - 2s 371us/step - loss: 15.0037 - val_loss: 15.0396\n",
      "Epoch 16/50\n",
      "5500/5500 [==============================] - 3s 501us/step - loss: 14.9653 - val_loss: 14.9761\n",
      "Epoch 17/50\n",
      "5500/5500 [==============================] - 2s 448us/step - loss: 14.9663 - val_loss: 15.0205\n",
      "Epoch 18/50\n",
      "5500/5500 [==============================] - 2s 386us/step - loss: 14.9217 - val_loss: 14.9777\n",
      "Epoch 19/50\n",
      "5500/5500 [==============================] - 2s 406us/step - loss: 14.8877 - val_loss: 14.9944\n",
      "Epoch 20/50\n",
      "5500/5500 [==============================] - 2s 384us/step - loss: 14.8861 - val_loss: 14.9039\n",
      "Epoch 21/50\n",
      "5500/5500 [==============================] - 2s 415us/step - loss: 14.8446 - val_loss: 14.8662\n",
      "Epoch 22/50\n",
      "5500/5500 [==============================] - 3s 465us/step - loss: 14.8489 - val_loss: 14.8327\n",
      "Epoch 23/50\n",
      "5500/5500 [==============================] - 2s 422us/step - loss: 14.8067 - val_loss: 14.8557\n",
      "Epoch 24/50\n",
      "5500/5500 [==============================] - 2s 412us/step - loss: 14.8073 - val_loss: 14.9871\n",
      "Epoch 25/50\n",
      "5500/5500 [==============================] - 2s 399us/step - loss: 14.8149 - val_loss: 14.9743\n",
      "Epoch 26/50\n",
      "5500/5500 [==============================] - 3s 476us/step - loss: 14.8292 - val_loss: 14.9250\n",
      "Epoch 27/50\n",
      "5500/5500 [==============================] - 3s 457us/step - loss: 14.8077 - val_loss: 14.8603\n",
      "Epoch 28/50\n",
      "5500/5500 [==============================] - 2s 388us/step - loss: 14.7653 - val_loss: 14.7846\n",
      "Epoch 29/50\n",
      "5500/5500 [==============================] - 2s 412us/step - loss: 14.7823 - val_loss: 14.7554\n",
      "Epoch 30/50\n",
      "5500/5500 [==============================] - 2s 444us/step - loss: 14.7608 - val_loss: 14.8497\n",
      "Epoch 31/50\n",
      "5500/5500 [==============================] - 2s 417us/step - loss: 14.7331 - val_loss: 14.7314\n",
      "Epoch 32/50\n",
      "5500/5500 [==============================] - 2s 449us/step - loss: 14.7426 - val_loss: 14.7510\n",
      "Epoch 33/50\n",
      "5500/5500 [==============================] - 3s 488us/step - loss: 14.7620 - val_loss: 14.7728\n",
      "Epoch 34/50\n",
      "5500/5500 [==============================] - 3s 496us/step - loss: 14.7485 - val_loss: 14.7231\n",
      "Epoch 35/50\n",
      "5500/5500 [==============================] - 3s 498us/step - loss: 14.7351 - val_loss: 14.7277\n",
      "Epoch 36/50\n",
      "5500/5500 [==============================] - 2s 443us/step - loss: 14.7415 - val_loss: 14.7303\n",
      "Epoch 37/50\n",
      "5500/5500 [==============================] - 2s 416us/step - loss: 14.7310 - val_loss: 14.7324\n",
      "Epoch 38/50\n",
      "5500/5500 [==============================] - 2s 433us/step - loss: 14.7173 - val_loss: 14.8337\n",
      "Epoch 39/50\n",
      "5500/5500 [==============================] - 3s 507us/step - loss: 14.7183 - val_loss: 14.7139\n",
      "Epoch 40/50\n",
      "5500/5500 [==============================] - 2s 404us/step - loss: 14.7180 - val_loss: 14.7068\n",
      "Epoch 41/50\n",
      "5500/5500 [==============================] - 2s 414us/step - loss: 14.7112 - val_loss: 14.7753\n",
      "Epoch 42/50\n",
      "5500/5500 [==============================] - 2s 355us/step - loss: 14.7105 - val_loss: 14.6965\n",
      "Epoch 43/50\n",
      "5500/5500 [==============================] - 3s 554us/step - loss: 14.7131 - val_loss: 14.7256\n",
      "Epoch 44/50\n",
      "5500/5500 [==============================] - 3s 569us/step - loss: 14.7075 - val_loss: 14.6843\n",
      "Epoch 45/50\n",
      "5500/5500 [==============================] - 2s 426us/step - loss: 14.7232 - val_loss: 14.7624\n",
      "Epoch 46/50\n",
      "5500/5500 [==============================] - 3s 525us/step - loss: 14.7066 - val_loss: 14.8084\n",
      "Epoch 47/50\n",
      "5500/5500 [==============================] - 3s 586us/step - loss: 14.7123 - val_loss: 14.6920\n",
      "Epoch 48/50\n",
      "5500/5500 [==============================] - 4s 640us/step - loss: 14.7039 - val_loss: 14.7936\n",
      "Epoch 49/50\n",
      "5500/5500 [==============================] - 3s 554us/step - loss: 14.6986 - val_loss: 14.6796\n",
      "Epoch 50/50\n",
      "5500/5500 [==============================] - 3s 481us/step - loss: 14.7020 - val_loss: 14.7684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cae4a748>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = vae.predict(input_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 1.0\n",
      "12.0 1.0\n",
      "7.0 0.99992776\n",
      "20.0 1.0\n",
      "12.0 1.0\n",
      "12.0 0.0\n",
      "17.0 1.0\n",
      "9.0 7.1602185e-06\n",
      "17.0 1.0\n",
      "17.0 0.0\n",
      "12.0 1.0\n",
      "25.0 1.0\n",
      "17.0 0.0\n",
      "25.0 1.0\n",
      "25.0 1.0\n",
      "12.0 1.0\n",
      "11.0 0.0\n",
      "17.0 1.0\n",
      "20.0 1.0\n",
      "12.0 1.0\n",
      "12.0 1.0\n",
      "12.0 1.0\n",
      "17.0 1.0\n",
      "4.0 0.09478525\n",
      "12.0 1.0\n",
      "15.0 1.0\n",
      "15.0 1.0\n",
      "5.0 3.0256373e-08\n",
      "5.0 0.24617836\n",
      "15.0 1.0\n",
      "12.0 1.0\n",
      "12.0 1.0\n",
      "5.0 4.85787e-10\n",
      "20.0 1.0\n",
      "17.0 0.0\n",
      "5.0 1.6034614e-29\n",
      "10.0 0.0\n",
      "17.0 0.0\n",
      "14.0 0.0\n",
      "12.0 1.0\n",
      "12.0 1.0\n",
      "12.0 1.0\n",
      "9.0 1.2562422e-10\n",
      "16.0 2.8970715e-10\n",
      "12.0 1.0\n",
      "18.0 0.0\n",
      "18.0 1.0\n",
      "10.0 0.0\n",
      "12.0 1.0\n",
      "6.0 0.0010068875\n",
      "11.0 3.2111261e-31\n",
      "17.0 1.0\n",
      "10.0 0.0\n",
      "12.0 1.0\n",
      "9.0 2.0049497e-35\n",
      "9.0 0.000599146\n",
      "9.0 0.09645598\n",
      "18.0 1.0\n",
      "7.0 1.0\n",
      "9.0 0.00010069027\n",
      "13.0 1.0\n",
      "24.0 0.0\n",
      "9.0 9.037526e-30\n",
      "9.0 3.5122136e-10\n",
      "9.0 0.29444292\n",
      "11.0 9.936364e-13\n",
      "7.0 1.0\n",
      "11.0 0.0\n",
      "3.0 4.5814584e-08\n",
      "11.0 0.83246714\n",
      "9.0 6.70416e-09\n",
      "11.0 0.0\n",
      "13.0 1.0\n",
      "12.0 1.0\n",
      "11.0 3.811254e-32\n",
      "11.0 1.6682986e-08\n",
      "15.0 1.0\n",
      "12.0 0.91614914\n",
      "11.0 1.9804025e-09\n",
      "7.0 1.0\n",
      "16.0 1.0\n",
      "10.0 0.999869\n",
      "10.0 1.0\n",
      "10.0 1.0\n",
      "16.0 1.0\n",
      "15.0 1.0\n",
      "16.0 1.0\n",
      "14.0 1.0\n",
      "9.0 0.0\n",
      "9.0 2.7429838e-27\n",
      "9.0 4.3344458e-19\n",
      "12.0 1.0\n",
      "9.0 0.012048272\n",
      "5.0 7.170607e-29\n",
      "14.0 1.0\n",
      "18.0 0.0\n",
      "7.0 0.9992569\n",
      "7.0 1.0\n",
      "12.0 1.0\n",
      "15.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(input_data[i].sum(), prediction[i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = ''\n",
    "for i in prediction[0]:\n",
    "    out += str(int(i))\n",
    "outinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
